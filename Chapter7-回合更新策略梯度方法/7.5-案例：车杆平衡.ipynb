{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x5794f70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        neurons = [input_size] + hidden_sizes\n",
    "        layers = []\n",
    "        for i in range(len(neurons) - 1):\n",
    "            layers.append(nn.Linear(neurons[i], neurons[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Linear(neurons[-1], output_size))\n",
    "        layers.append(nn.Softmax())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同策策略梯度算法智能体类\n",
    "\n",
    "class VPGAgent(object):\n",
    "    \n",
    "    def __init__(self, env, policy_kwargs, baseline_kwargs=None, gamma=0.99):\n",
    "        observation_dim = env.observation_space.shape[0]\n",
    "        self.action_n = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.trajectory = []\n",
    "\n",
    "        self.policy_net = DQN(observation_dim, policy_kwargs['hidden_sizes'], self.action_n)\n",
    "        self.policy_opt = optim.Adam(self.policy_net.parameters(), lr=policy_kwargs['learning_rate'])\n",
    "        \n",
    "        if baseline_kwargs:\n",
    "            self.baseline_net = DQN(observation_dim, baseline_kwargs['hidden_sizes'], 1)\n",
    "            self.baseline_opt = optim.Adam(self.baseline_net.parameters(), lr=baseline_kwargs['learning_rate'])\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def __tensor2numpy(tensor):\n",
    "        return tensor.cpu().detach().numpy()\n",
    "    \n",
    "    def decide(self, observation):\n",
    "        self.policy_net.eval()\n",
    "        probs = self.policy_net(torch.tensor(observation[np.newaxis]).float())\n",
    "        probs = self.__tensor2numpy(probs)[0]\n",
    "        action = np.random.choice(self.action_n, p=probs)\n",
    "        return action\n",
    "    \n",
    "    def learn(self, observation, action, reward, done):\n",
    "        self.trajectory.append((observation, action, reward))\n",
    "        \n",
    "        if done:\n",
    "            df = pd.DataFrame(data=self.trajectory, columns=['observation', 'action', 'reward'])\n",
    "            df['discount'] = self.gamma ** df.index.to_series()\n",
    "            df['discounted_reward'] = df['discount'] * df['reward']\n",
    "            df['discounted_return'] = df['discounted_reward'][::-1].cumsum()\n",
    "            df['psi'] = df['discounted_return']\n",
    "            \n",
    "            x = torch.tensor(np.stack(df['observation'])).float()\n",
    "            if hasattr(self, 'baseline_net'):\n",
    "                self.baseline_net.eval()\n",
    "                df['baseline'] = self.__tensor2numpy(self.baseline_net(x))\n",
    "                df['psi'] -= df['baseline'] * df['discount']\n",
    "                df['return'] = df['discount_return'] / df['discount']\n",
    "                y = torch.tensor(df['return'].values[:, np.newaxis]).float()\n",
    "                self.baseline_net.train()\n",
    "                y_hat = self.baseline_net(x)\n",
    "                loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "                self.baseline_opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.baseline_opt.step()\n",
    "            \n",
    "            y = torch.tensor(np.eye(self.action_n)[df['action']] * df['psi'].values[:, np.newaxis]).float()\n",
    "            self.policy_net.train()\n",
    "            y_hat = self.policy_net(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "            self.policy_opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.policy_opt.step()\n",
    "\n",
    "            self.trajectory = []\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 智能体和环境交互一个回合的代码\n",
    "\n",
    "def play_montecarlo(env, agent, render=False, train=False):\n",
    "    episode_reward = 0.0\n",
    "    observation = env.reset()\n",
    "    \n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        \n",
    "        action = agent.decide(observation)\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        \n",
    "        if train:\n",
    "            agent.learn(observation, action, reward, done)\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        observation = next_observation\n",
    "    \n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd25b5f62084b0fbcef1f099464b9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programdata\\miniconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均回合奖励 = 950.0 / 100 = 9.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 不带基线的简单策略梯度算法\n",
    "\n",
    "policy_kwargs = dict(hidden_sizes=[128,], learning_rate=0.01)\n",
    "agent = VPGAgent(env, policy_kwargs=policy_kwargs)\n",
    "\n",
    "# 训练\n",
    "episodes = 2000\n",
    "episode_rewards = []\n",
    "for episode in tqdm(range(episodes)):\n",
    "    episode_reward = play_montecarlo(env, agent, train=True)\n",
    "    episode_rewards.append(episode_reward)\n",
    "plt.plot(episode_rewards)\n",
    "\n",
    "# 测试\n",
    "episode_rewards = [play_montecarlo(env, agent, train=False) for _ in range(100)]\n",
    "print('平均回合奖励 = {} / {} = {}'.format(sum(episode_rewards), len(episode_rewards), np.mean(episode_rewards)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
